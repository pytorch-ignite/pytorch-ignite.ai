<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyTorch-Ignite</title><link>https://pytorch-ignite.ai/</link><description>Recent content on PyTorch-Ignite</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://pytorch-ignite.ai/index.xml" rel="self" type="application/rss+xml"/><item><title>GAN evaluation using FID and IS</title><link>https://pytorch-ignite.ai/posts/gan-evaluation-with-fid-and-is/</link><pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/posts/gan-evaluation-with-fid-and-is/</guid><description>&lt;p>In this notebook, two &lt;code>PyTorch-Ignite&lt;/code>&amp;rsquo;s metrics to evaluate &lt;em>Generative Adversarial Networks&lt;/em> (or GAN in short) are introduced :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Frechet Inception Distance&lt;/strong>, details can be found in &lt;a href="https://arxiv.org/pdf/1706.08500.pdf">&lt;code>Heusel et al. 2002&lt;/code>&lt;/a>&lt;/li>
&lt;li>&lt;strong>Inception Score&lt;/strong>, details can be found in &lt;a href="https://arxiv.org/pdf/1801.01973.pdf">&lt;code>Barratt et al. 2018&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See &lt;a href="https://pytorch.org/ignite/metrics.html#complete-list-of-metrics">here&lt;/a> for more details about the implementation of the metrics in &lt;a href="https://github.com/pytorch/ignite">PyTorch-Ignite&lt;/a>.&lt;/p>
&lt;p>Most of the code here is from &lt;a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">DCGAN example&lt;/a> in &lt;a href="https://github.com/pytorch/examples">pytorch/examples&lt;/a>. In addition to the original tutorial, this notebook will use in-built GAN based metric in &lt;code>ignite.metrics&lt;/code> to evaluate Frechet Inception Distnace and Inception Score and showcase other metric based features in &lt;code>ignite&lt;/code>.&lt;/p></description></item><item><title>How to effectively increase batch size on limited compute</title><link>https://pytorch-ignite.ai/how-to-guides/gradient-accumulation/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/gradient-accumulation/</guid><description>&lt;p>To effectively increase the batch size on limited GPU resources, follow
this simple best practice.&lt;/p></description></item><item><title>How to install PyTorch-Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/installation/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/installation/</guid><description>Install PyTorch-Ignite from pip, conda, source or use pre-built docker images</description></item><item><title>How to work with data iterators</title><link>https://pytorch-ignite.ai/how-to-guides/data-iterator/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/data-iterator/</guid><description>&lt;p>When the data provider for training or validation is an iterator
(infinite or finite with known or unknown size), here are some basic
examples of how to setup trainer or evaluator.&lt;/p></description></item><item><title>How to use FastaiLRFinder with Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/fastai-lr-finder/</link><pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/fastai-lr-finder/</guid><description>&lt;p>This how-to guide demonstrates how we can leverage the &lt;a href="https://pytorch.org/ignite/generated/ignite.handlers.lr_finder.FastaiLRFinder.html">&lt;code>FastaiLRFinder&lt;/code>&lt;/a> handler to find an optimal learning rate to train our model on. We will compare the results produced with and without using the handler for better understanding.&lt;/p></description></item><item><title>Getting Started</title><link>https://pytorch-ignite.ai/tutorials/getting-started/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/getting-started/</guid><description>&lt;p>Welcome to &lt;strong>PyTorch-Ignite&lt;/strong>â€™s quick start guide that covers the
essentials of getting a project up and running while walking through
basic concepts of Ignite. In just a few lines of code, you can get your
model trained and validated. The complete code can be found at the end
of this guide.&lt;/p></description></item><item><title>Introducing PyTorch-Ignite's Code Generator v0.2.0</title><link>https://pytorch-ignite.ai/posts/introducing-code-generator-v020/</link><pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/posts/introducing-code-generator-v020/</guid><description>&lt;p>Along with the &lt;a href="https://github.com/pytorch/ignite/releases/tag/v0.4.5">PyTorch-Ignite 0.4.5 release&lt;/a>, we are excited to announce the new release of the web application for generating PyTorch-Ignite&amp;rsquo;s training pipelines. This blog post is an overview of the key features and updates of the &lt;a href="https://github.com/pytorch-ignite/code-generator/releases/tag/v0.2.0">Code Generator v0.2.0 project release&lt;/a>.&lt;/p></description></item><item><title>Distributed Training Made Easy with PyTorch-Ignite</title><link>https://pytorch-ignite.ai/posts/distributed-made-easy-with-ignite/</link><pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/posts/distributed-made-easy-with-ignite/</guid><description>&lt;p>Writing &lt;a href="https://en.wikipedia.org/wiki/Agnostic_(data)">agnostic&lt;/a> &lt;a href="https://pytorch.org/tutorials/beginner/dist_overview.html">distributed code&lt;/a> that supports different platforms, hardware configurations (GPUs, TPUs) and communication frameworks is tedious. In this blog, we will discuss how &lt;a href="https://pytorch.org/ignite/">PyTorch-Ignite&lt;/a> solves this problem with minimal code change.&lt;/p></description></item><item><title>Introduction to PyTorch-Ignite</title><link>https://pytorch-ignite.ai/posts/introduction/</link><pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/posts/introduction/</guid><description>&lt;p>This post is a general introduction of PyTorch-Ignite. It intends to give a brief but illustrative overview of what PyTorch-Ignite can offer for Deep Learning enthusiasts, professionals and researchers. Following the same philosophy as PyTorch, PyTorch-Ignite aims to keep it simple, flexible and extensible but performant and scalable.&lt;/p>
&lt;p>Throughout this tutorial, we will introduce the basic concepts of PyTorch-Ignite with the training and evaluation of a MNIST classifier as a beginner application case. We also assume that the reader is familiar with PyTorch.&lt;/p></description></item><item><title>Community</title><link>https://pytorch-ignite.ai/community/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/community/</guid><description>PyTorch-Ignite is a community-driven open source project developed by a passionate group of contributors. Please read the PyTorch-Ignite Code of Conduct for guidance on how to interact with other community members in a way that makes the community thrive.
GitHub Issue Tracker GitHub issuse tracker should be used for bug reporting, feature requests, documentation improvements, and user feedbacks.
GitHub Discussions GitHub Discussions can be used for discussing PyTorch-Ignite related questions and help.</description></item><item><title>Ecosystem</title><link>https://pytorch-ignite.ai/ecosystem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/ecosystem/</guid><description>If your project implements a paper, represents other use-cases not covered in our official tutorials, Kaggle competition&amp;rsquo;s code, or just your code presents interesting results and uses PyTorch-Ignite. We would like to add your project to this list, so please open an issue here: https://github.com/pytorch-ignite/pytorch-ignite.ai/issues with brief description of the project.
The list below is unexhausted list of references that we are aware of.
Research Papers BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning A Model to Search for Synthesizable Molecules Localised Generative Flows Extracting T Cell Function and Differentiation Characteristics from the Biomedical Literature Variational Information Distillation for Knowledge Transfer XPersona: Evaluating Multilingual Personalized Chatbot CNN-CASS: CNN for Classification of Coronary Artery Stenosis Score in MPR Images Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog Adversarial Decomposition of Text Representation Uncertainty Estimation Using a Single Deep Deterministic Neural Network DeepSphere: a graph-based spherical CNN Norm-in-Norm Loss with Faster Convergence and Better Performance for Image Quality Assessment Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets Training Deep Signature Transforms Neural CDEs for Long Time-Series via the Log-ODE Method Volumetric Grasping Network Mood Classification using Listening Data Deterministic Uncertainty Estimation (DUE) PyTorch-Hebbian: facilitating local learning in a deep learning framework Stochastic Weight Matrix-Based Regularization Methods for Deep Neural Networks Learning explanations that are hard to vary The role of disentanglement in generalisation A Probabilistic Programming Approach to Protein Structure Superposition PadChest: A large chest x-ray image dataset with multi-label annotated reports Blog articles, tutorials, books State-of-the-Art Conversational AI with Transfer Learning Tutorial on Transfer Learning in NLP held at NAACL 2019 Deep-Reinforcement-Learning-Hands-On-Second-Edition, published by Packt Once Upon a Repository: How to Write Readable, Maintainable Code with PyTorch The Hero Rises: Build Your Own SSD Using Optuna to Optimize PyTorch Ignite Hyperparameters Toolkits Project MONAI - AI Toolkit for Healthcare Imaging DeepSeismic - Deep Learning for Seismic Imaging and Interpretation Nussl - a flexible, object-oriented Python audio source separation library Others Implementation of &amp;ldquo;Attention is All You Need&amp;rdquo; paper Implementation of DropBlock: A regularization method for convolutional networks in PyTorch Kaggle Kuzushiji Recognition: 2nd place solution Unsupervised Data Augmentation experiments in PyTorch Hyperparameters tuning with Optuna Logging with ChainerUI FixMatch experiments in PyTorch and Ignite (CTA dataaug policy) Kaggle Birdcall Identification Competition: 1st place solution See other projects at &amp;ldquo;Used by&amp;rdquo;.</description></item><item><title>How to do time profiling</title><link>https://pytorch-ignite.ai/how-to-guides/time-profiling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/time-profiling/</guid><description>Learn how to get the time breakdown for individual epochs during training, individual events, all handlers corresponding to an event, individual handlers, data loading and data processing using Engine&amp;rsquo;s State, BasicTimeProfiler and HandlersTimeProfiler.</description></item></channel></rss>