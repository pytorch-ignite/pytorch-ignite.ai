<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyTorch-Ignite</title><link>https://pytorch-ignite.ai/</link><description>Recent content on PyTorch-Ignite</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://pytorch-ignite.ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Distributed Training on CPUs, GPUs or TPUs</title><link>https://pytorch-ignite.ai/tutorials/intermediate/01-cifar10-distributed/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/intermediate/01-cifar10-distributed/</guid><description>&lt;h1 id="distributed-training-with-ignite-on-cifar10">
&lt;a href="#distributed-training-with-ignite-on-cifar10" class="header-anchor">
Distributed Training with Ignite on CIFAR10
&lt;/a>
&lt;/h1>&lt;p>This tutorial is a brief introduction on how you can do distributed training with Ignite on one or more CPUs, GPUs or TPUs. We will also introduce several helper functions and Ignite concepts (setup common training handlers, save to/ load from checkpoints, etc.) which you can easily incorporate in your code.&lt;/p></description></item><item><title>How to install PyTorch-Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/01-installation/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/01-installation/</guid><description>Install PyTorch-Ignite from pip, conda, source or use pre-built docker images</description></item><item><title>Getting Started</title><link>https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/</guid><description>&lt;h1 id="getting-started">
&lt;a href="#getting-started" class="header-anchor">
Getting Started
&lt;/a>
&lt;/h1>&lt;p>Welcome to &lt;strong>PyTorch-Ignite&lt;/strong>â€™s quick start guide that covers the
essentials of getting a project up and running while walking through
basic concepts of Ignite. In just a few lines of code, you can get your
model trained and validated. The complete code can be found at the end
of this guide.&lt;/p></description></item><item><title>Collective Communication with Ignite</title><link>https://pytorch-ignite.ai/tutorials/advanced/01-collective-communication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/advanced/01-collective-communication/</guid><description>&lt;h1 id="collective-communication-with-ignite">
&lt;a href="#collective-communication-with-ignite" class="header-anchor">
Collective Communication with Ignite
&lt;/a>
&lt;/h1>&lt;p>In this tutorial, we will see how to use advanced distributed functions like &lt;code>all_reduce()&lt;/code>, &lt;code>all_gather()&lt;/code>, &lt;code>broadcast()&lt;/code> and &lt;code>barrier()&lt;/code>. We will discuss unique use cases for all of them and represent them visually.&lt;/p></description></item><item><title>Engine</title><link>https://pytorch-ignite.ai/concepts/01-engine/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/concepts/01-engine/</guid><description>How does &lt;code>Engine&lt;/code> work and how to customise it as per your needs.</description></item><item><title>Machine Translation using PyTorch Ignite</title><link>https://pytorch-ignite.ai/tutorials/intermediate/02-machine_translation_using_pytorch_ignite/</link><pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/intermediate/02-machine_translation_using_pytorch_ignite/</guid><description>&lt;h1 id="machine-translation-using-pytorch-ignite">
&lt;a href="#machine-translation-using-pytorch-ignite" class="header-anchor">
Machine Translation using PyTorch Ignite
&lt;/a>
&lt;/h1>&lt;p>This tutorial is a brief introduction on how you can train a machine translation model (or any other seq2seq model) using PyTorch Ignite.
This notebook uses Models, Dataset and Tokenizers from Huggingface, hence they can be easily replaced by other models from the ðŸ¤— Hub.&lt;/p></description></item><item><title>Transformers for Text Classification with IMDb Reviews</title><link>https://pytorch-ignite.ai/tutorials/beginner/02-transformers-text-classification/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/beginner/02-transformers-text-classification/</guid><description>&lt;h1 id="transformers-for-text-classification-with-imdb-reviews">
&lt;a href="#transformers-for-text-classification-with-imdb-reviews" class="header-anchor">
Transformers for Text Classification with IMDb Reviews
&lt;/a>
&lt;/h1>&lt;p>In this tutorial we will fine tune a model from the Transformers library for text classification using PyTorch-Ignite. We will be following the
&lt;a href="https://huggingface.co/transformers/training.html" target="_blank" rel="noopener noreferrer">Fine-tuning a pretrained model&lt;/a> tutorial for preprocessing text and defining the model, optimizer and dataloaders.&lt;/p></description></item><item><title>Events and Handlers</title><link>https://pytorch-ignite.ai/concepts/02-events-and-handlers/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/concepts/02-events-and-handlers/</guid><description>Compose any training pipeline with the true power of events and handlers.</description></item><item><title>How to convert pure PyTorch code to Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/02-convert-pytorch-to-ignite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/02-convert-pytorch-to-ignite/</guid><description>&lt;h1 id="how-to-convert-pure-pytorch-code-to-ignite">
&lt;a href="#how-to-convert-pure-pytorch-code-to-ignite" class="header-anchor">
How to convert pure PyTorch code to Ignite
&lt;/a>
&lt;/h1>&lt;p>In this guide, we will show how PyTorch code components can be converted into compact and flexible PyTorch-Ignite code.&lt;/p></description></item><item><title>Reinforcement Learning with Ignite</title><link>https://pytorch-ignite.ai/tutorials/intermediate/03-reinforcement-learning/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/intermediate/03-reinforcement-learning/</guid><description>&lt;h1 id="reinforcement-learning-with-ignite">
&lt;a href="#reinforcement-learning-with-ignite" class="header-anchor">
Reinforcement Learning with Ignite
&lt;/a>
&lt;/h1>&lt;p>In this tutorial we will implement a
&lt;a href="http://www.scholarpedia.org/article/Policy_gradient_methods" target="" rel="">policy gradient based algorithm&lt;/a> called
&lt;a href="http://www.cs.toronto.edu/~tingwuwang/REINFORCE.pdf" target="" rel="">Reinforce&lt;/a> and use it to solve OpenAI&amp;rsquo;s
&lt;a href="https://github.com/openai/gym/wiki/CartPole-v0" target="_blank" rel="noopener noreferrer">Cartpole problem&lt;/a> using PyTorch-Ignite.&lt;/p></description></item><item><title>How to do time profiling</title><link>https://pytorch-ignite.ai/how-to-guides/03-time-profiling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/03-time-profiling/</guid><description>Learn how to get the time breakdown for individual epochs during training, individual events, all handlers corresponding to an event, individual handlers, data loading and data processing using Engine&amp;rsquo;s State, BasicTimeProfiler and HandlersTimeProfiler.</description></item><item><title>State</title><link>https://pytorch-ignite.ai/concepts/03-state/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/concepts/03-state/</guid><description>Best way to store useful information about &lt;code>Engine&lt;/code>.</description></item><item><title>How to use FastaiLRFinder with Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/04-fastai-lr-finder/</link><pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/04-fastai-lr-finder/</guid><description>&lt;h1 id="how-to-use-fastailrfinder-with-ignite">
&lt;a href="#how-to-use-fastailrfinder-with-ignite" class="header-anchor">
How to use FastaiLRFinder with Ignite
&lt;/a>
&lt;/h1>&lt;p>This how-to guide demonstrates how we can leverage the
&lt;a href="https://pytorch.org/ignite/generated/ignite.handlers.lr_finder.FastaiLRFinder.html" target="_blank" rel="noopener noreferrer">&lt;code>FastaiLRFinder&lt;/code>&lt;/a> handler to find an optimal learning rate to train our model on. We will compare the results produced with and without using the handler for better understanding.&lt;/p></description></item><item><title>Metrics</title><link>https://pytorch-ignite.ai/concepts/04-metrics/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/concepts/04-metrics/</guid><description>How we compute metrics internally.</description></item><item><title>How to effectively increase batch size on limited compute</title><link>https://pytorch-ignite.ai/how-to-guides/05-gradient-accumulation/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/05-gradient-accumulation/</guid><description>&lt;h1 id="how-to-effectively-increase-batch-size-on-limited-compute">
&lt;a href="#how-to-effectively-increase-batch-size-on-limited-compute" class="header-anchor">
How to effectively increase batch size on limited compute
&lt;/a>
&lt;/h1>&lt;p>To effectively increase the batch size on limited GPU resources, follow
this simple best practice.&lt;/p></description></item><item><title>How to work with data iterators</title><link>https://pytorch-ignite.ai/how-to-guides/06-data-iterator/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/06-data-iterator/</guid><description>&lt;h1 id="how-to-work-with-data-iterators">
&lt;a href="#how-to-work-with-data-iterators" class="header-anchor">
How to work with data iterators
&lt;/a>
&lt;/h1>&lt;p>When the data provider for training or validation is an iterator
(infinite or finite with known or unknown size), here are some basic
examples of how to setup trainer or evaluator.&lt;/p></description></item><item><title>How to do Cross Validation in Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/07-cross-validation/</link><pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/07-cross-validation/</guid><description>&lt;h1 id="how-to-do-cross-validation-in-ignite">
&lt;a href="#how-to-do-cross-validation-in-ignite" class="header-anchor">
How to do Cross Validation in Ignite
&lt;/a>
&lt;/h1>&lt;p>This how-to guide demonstrates how we can do Cross Validation using the k-fold technique with PyTorch-Ignite and save the best results.&lt;/p>
&lt;p>Cross Validation is useful for tuning model parameters or when the available data is insufficient to properly test&lt;/p></description></item><item><title>How to create Custom Events based on Forward or Backward Pass</title><link>https://pytorch-ignite.ai/how-to-guides/08-custom-events/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/08-custom-events/</guid><description>Learn how to create custom events that depend on the loss calculated, backward pass, optimization step, etc.</description></item><item><title>How to switch data provider during training</title><link>https://pytorch-ignite.ai/how-to-guides/09-switch-data-training/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/09-switch-data-training/</guid><description>Example on how to switch data during training after some number of iterations</description></item><item><title>How to use Loggers</title><link>https://pytorch-ignite.ai/how-to-guides/10-loggers/</link><pubDate>Mon, 25 Oct 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/10-loggers/</guid><description>&lt;h1 id="how-to-use-loggers">
&lt;a href="#how-to-use-loggers" class="header-anchor">
How to use Loggers
&lt;/a>
&lt;/h1>&lt;p>This how-to guide demonstrates the usage of loggers with Ignite. As part of this guide, we will be using the
&lt;a href="https://clear.ml/docs/latest/docs/fundamentals/logger/" target="_blank" rel="noopener noreferrer">ClearML&lt;/a> logger and also highlight how this code can be easily modified to make use of other loggers. You can see all the other loggers supported
&lt;a href="https://pytorch.org/ignite/contrib/handlers.html#loggers" target="_blank" rel="noopener noreferrer">here&lt;/a>.&lt;/p></description></item><item><title>How to load checkpoint and resume training</title><link>https://pytorch-ignite.ai/how-to-guides/11-load-checkpoint/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/11-load-checkpoint/</guid><description>This example demonstrates how you can save and load a checkpoint then resume training.</description></item><item><title>Bridging Data Science Tools with PyTorch-Ignite's Code-Generator and Nebari</title><link>https://pytorch-ignite.ai/blog/integrations-with-code-generator-during-quansight-intern/</link><pubDate>Wed, 20 Sep 2023 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/blog/integrations-with-code-generator-during-quansight-intern/</guid><description>Bridging Data Science Tools with PyTorch-Ignite&amp;rsquo;s Code-Generator and Nebari To the readers, I am Aryan Gupta( @guptaaryan16), an EE Junior at IIT Roorkee, and this summer, I had a chance to work on PyTorch-Igniteâ€™s Code-Generator project, a tailor-made web application to help machine learning researchers and enthusiasts and also keeping in mind the growing Kaggle community.
Crossposted from https://labs.quansight.org/blog
The project itself Letâ€™s see the project itself.</description></item><item><title>Sangho's Internship at Quansight with PyTorch-Ignite project</title><link>https://pytorch-ignite.ai/blog/pytorch-ignite-during-quansight-internship/</link><pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/blog/pytorch-ignite-during-quansight-internship/</guid><description>&lt;p>Hey, I&amp;rsquo;m Sangho Lee, a master&amp;rsquo;s student from Seoul National University.
I have participated in the
&lt;a href="https://pytorch-ignite.ai/" target="_blank" rel="noopener noreferrer">PyTorch-Ignite&lt;/a> project internship at Quansight Labs, working on test code improvements and features for distributed computations.&lt;/p></description></item><item><title>GAN evaluation using FID and IS</title><link>https://pytorch-ignite.ai/blog/gan-evaluation-with-fid-and-is/</link><pubDate>Wed, 11 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/blog/gan-evaluation-with-fid-and-is/</guid><description>&lt;h2 id="gan-evaluation--the-frechet-inception-distance-and-inception-score-metrics">
&lt;a href="#gan-evaluation--the-frechet-inception-distance-and-inception-score-metrics" class="header-anchor">
GAN Evaluation : the Frechet Inception Distance and Inception Score metrics
&lt;/a>
&lt;/h2>&lt;p>
&lt;img src="https://pytorch-ignite.ai/_images/2021-08-11-GAN-evaluation-using-FID-and-IS_97_1.png" alt="GAN evaluation results using FID and IS" width="120" height="100%" loading="lazy"
class="rounded-lg mx-auto w-4/5 lg:w-3/5" />
&lt;/p>
&lt;p>In this notebook, two &lt;code>PyTorch-Ignite&lt;/code>&amp;rsquo;s metrics to evaluate &lt;em>Generative Adversarial Networks&lt;/em> (or GAN in short) are introduced :&lt;/p>
&lt;ul>
&lt;li>&lt;strong>Frechet Inception Distance&lt;/strong>, details can be found in
&lt;a href="https://arxiv.org/pdf/1706.08500.pdf" target="_blank" rel="noopener noreferrer">&lt;code>Heusel et al. 2002&lt;/code>&lt;/a>&lt;/li>
&lt;li>&lt;strong>Inception Score&lt;/strong>, details can be found in
&lt;a href="https://arxiv.org/pdf/1801.01973.pdf" target="_blank" rel="noopener noreferrer">&lt;code>Barratt et al. 2018&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>See
&lt;a href="https://pytorch.org/ignite/metrics.html#complete-list-of-metrics" target="_blank" rel="noopener noreferrer">here&lt;/a> for more details about the implementation of the metrics in
&lt;a href="https://github.com/pytorch/ignite" target="_blank" rel="noopener noreferrer">PyTorch-Ignite&lt;/a>.&lt;/p>
&lt;p>Most of the code here is from
&lt;a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html" target="_blank" rel="noopener noreferrer">DCGAN example&lt;/a> in
&lt;a href="https://github.com/pytorch/examples" target="_blank" rel="noopener noreferrer">pytorch/examples&lt;/a>. In addition to the original tutorial, this notebook will use in-built GAN based metric in &lt;code>ignite.metrics&lt;/code> to evaluate Frechet Inception Distnace and Inception Score and showcase other metric based features in &lt;code>ignite&lt;/code>.&lt;/p></description></item><item><title>Introducing PyTorch-Ignite's Code Generator v0.2.0</title><link>https://pytorch-ignite.ai/blog/introducing-code-generator-v020/</link><pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/blog/introducing-code-generator-v020/</guid><description>&lt;h1 id="introducing-pytorch-ignites-code-generator-v020">
&lt;a href="#introducing-pytorch-ignites-code-generator-v020" class="header-anchor">
Introducing PyTorch-Ignite&amp;rsquo;s Code Generator v0.2.0
&lt;/a>
&lt;/h1>&lt;p>
&lt;img src="https://raw.githubusercontent.com/pytorch-ignite/code-generator/main/src/assets/code-generator-demo.gif" alt="code-generator-demo GIF" width="120" height="100%" loading="lazy"
class="rounded-lg mx-auto w-4/5 lg:w-3/5" />
&lt;/p>
&lt;p>Along with the
&lt;a href="https://github.com/pytorch/ignite/releases/tag/v0.4.5" target="_blank" rel="noopener noreferrer">PyTorch-Ignite 0.4.5 release&lt;/a>, we are excited to announce the new release of the web application for generating PyTorch-Ignite&amp;rsquo;s training pipelines. This blog post is an overview of the key features and updates of the
&lt;a href="https://github.com/pytorch-ignite/code-generator/releases/tag/v0.2.0" target="_blank" rel="noopener noreferrer">Code Generator v0.2.0 project release&lt;/a>.&lt;/p></description></item><item><title>Distributed Training Made Easy with PyTorch-Ignite</title><link>https://pytorch-ignite.ai/blog/distributed-made-easy-with-ignite/</link><pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/blog/distributed-made-easy-with-ignite/</guid><description>&lt;h1 id="distributed-training-made-easy-with-pytorch-ignite">
&lt;a href="#distributed-training-made-easy-with-pytorch-ignite" class="header-anchor">
Distributed Training Made Easy with PyTorch-Ignite
&lt;/a>
&lt;/h1>&lt;p>
&lt;img src="https://pytorch-ignite.ai/_images/ignite_logo_mixed.svg" alt="PyTorch-Ignite logo" width="120" height="100%" loading="lazy"
class="rounded-lg mx-auto w-4/5 lg:w-3/5" />
&lt;/p>
&lt;p>Writing
&lt;a href="https://en.wikipedia.org/wiki/Agnostic_%28data%29" target="_blank" rel="noopener noreferrer">agnostic&lt;/a>
&lt;a href="https://pytorch.org/tutorials/beginner/dist_overview.html" target="_blank" rel="noopener noreferrer">distributed code&lt;/a> that supports different platforms, hardware configurations (GPUs, TPUs) and communication frameworks is tedious. In this blog, we will discuss how
&lt;a href="https://pytorch.org/ignite/" target="_blank" rel="noopener noreferrer">PyTorch-Ignite&lt;/a> solves this problem with minimal code change.&lt;/p></description></item><item><title>Introduction to PyTorch-Ignite</title><link>https://pytorch-ignite.ai/blog/introduction/</link><pubDate>Thu, 10 Sep 2020 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/blog/introduction/</guid><description>&lt;h1 id="introduction-to-pytorch-ignite">
&lt;a href="#introduction-to-pytorch-ignite" class="header-anchor">
Introduction to PyTorch-Ignite
&lt;/a>
&lt;/h1>&lt;p>
&lt;img src="https://i.ibb.co/x8Bhqhj/habr-pytorch-ignite-image.png" alt="Ignite your PyTorch neural networks image" width="120" height="100%" loading="lazy"
class="rounded-lg mx-auto w-4/5 lg:w-3/5" />
&lt;/p>
&lt;p>This post is a general introduction of PyTorch-Ignite. It intends to give a brief but illustrative overview of what PyTorch-Ignite can offer for Deep Learning enthusiasts, professionals and researchers. Following the same philosophy as PyTorch, PyTorch-Ignite aims to keep it simple, flexible and extensible but performant and scalable.&lt;/p>
&lt;p>Throughout this tutorial, we will introduce the basic concepts of PyTorch-Ignite with the training and evaluation of a MNIST classifier as a beginner application case. We also assume that the reader is familiar with PyTorch.&lt;/p></description></item><item><title/><link>https://pytorch-ignite.ai/tutorials/others/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/others/</guid><description>Other Tutorials Text Classification using Convolutional Neural Networks Variational Auto Encoders Convolutional Neural Networks for Classifying Fashion-MNIST Dataset Training Cycle-GAN on Horses to Zebras with Nvidia/Apex - logs on W&amp;amp;B Another training Cycle-GAN on Horses to Zebras with Native Torch CUDA AMP - logs on W&amp;amp;B Finetuning EfficientNet-B0 on CIFAR100 Hyperparameters tuning with Ax Benchmark mixed precision training on Cifar100: torch.</description></item><item><title>Code of Conduct</title><link>https://pytorch-ignite.ai/about/coc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/about/coc/</guid><description>Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to make participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.
Our Standards Examples of behavior that contributes to creating a positive environment include:</description></item><item><title>Community</title><link>https://pytorch-ignite.ai/about/community/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/about/community/</guid><description>Community PyTorch-Ignite is a community-driven open source project developed by a passionate group of contributors. Please read the PyTorch-Ignite Code of Conduct for guidance on how to interact with other community members in a way that makes the community thrive.
GitHub Issue Tracker GitHub issuse tracker should be used for bug reporting, feature requests, documentation improvements, and user feedbacks.
GitHub Discussions GitHub Discussions can be used for discussing PyTorch-Ignite related questions and help.</description></item><item><title>Contribution Guide</title><link>https://pytorch-ignite.ai/about/contribution-guide/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/about/contribution-guide/</guid><description>PyTorch-Ignite Contribution Guide Ignite&amp;rsquo;s community is growing and if you&amp;rsquo;re reading this, there&amp;rsquo;s a good chance you&amp;rsquo;re ready to join it. So&amp;hellip; welcome!
Now we&amp;rsquo;ll answer both what the community can do for you and what you can do for the community.
Code of Conduct Our Code of Conduct is a guide to make it easier to enrich all of us and the technical communities in which we participate.</description></item><item><title>Ecosystem</title><link>https://pytorch-ignite.ai/ecosystem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/ecosystem/</guid><description>Ecosystem If your project implements a paper, represents other use-cases not covered in our official tutorials, Kaggle competition&amp;rsquo;s code, or just your code presents interesting results and uses PyTorch-Ignite. We would like to add your project to this list, so please open an issue here: https://github.com/pytorch-ignite/pytorch-ignite.ai/issues with brief description of the project.
The list below is unexhausted list of references that we are aware of.
Research Papers BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning A Model to Search for Synthesizable Molecules Localised Generative Flows Extracting T Cell Function and Differentiation Characteristics from the Biomedical Literature Variational Information Distillation for Knowledge Transfer XPersona: Evaluating Multilingual Personalized Chatbot CNN-CASS: CNN for Classification of Coronary Artery Stenosis Score in MPR Images Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog Adversarial Decomposition of Text Representation Uncertainty Estimation Using a Single Deep Deterministic Neural Network DeepSphere: a graph-based spherical CNN Norm-in-Norm Loss with Faster Convergence and Better Performance for Image Quality Assessment Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets Training Deep Signature Transforms Neural CDEs for Long Time-Series via the Log-ODE Method Volumetric Grasping Network Mood Classification using Listening Data Deterministic Uncertainty Estimation (DUE) PyTorch-Hebbian: facilitating local learning in a deep learning framework Stochastic Weight Matrix-Based Regularization Methods for Deep Neural Networks Learning explanations that are hard to vary The role of disentanglement in generalisation A Probabilistic Programming Approach to Protein Structure Superposition PadChest: A large chest x-ray image dataset with multi-label annotated reports Causal-BALD: Deep Bayesian Active Learning of Outcomes to Infer Treatment-Effects from Observational Data Blog articles, tutorials, books State-of-the-Art Conversational AI with Transfer Learning Tutorial on Transfer Learning in NLP held at NAACL 2019 Deep-Reinforcement-Learning-Hands-On-Second-Edition, published by Packt Once Upon a Repository: How to Write Readable, Maintainable Code with PyTorch The Hero Rises: Build Your Own SSD Using Optuna to Optimize PyTorch Ignite Hyperparameters Toolkits Project MONAI - AI Toolkit for Healthcare Imaging DeepSeismic - Deep Learning for Seismic Imaging and Interpretation Nussl - a flexible, object-oriented Python audio source separation library xFraud: Explainable Fraud Transaction Detection on Heterogeneous Graphs PyTorch Adapt - A fully featured and modular domain adaptation library gnina-torch: PyTorch implementation of GNINA scoring function PyTorch-Ignite Code-generator: The easiest way to create your training scripts with PyTorch-Ignite Others Implementation of &amp;ldquo;Attention is All You Need&amp;rdquo; paper Implementation of DropBlock: A regularization method for convolutional networks in PyTorch Kaggle Kuzushiji Recognition: 2nd place solution Unsupervised Data Augmentation experiments in PyTorch Hyperparameters tuning with Optuna Logging with ChainerUI FixMatch experiments in PyTorch and Ignite (CTA dataaug policy) Kaggle Birdcall Identification Competition: 1st place solution Logging with Aim - An open-source experiment tracker See other projects at &amp;ldquo;Used by&amp;rdquo;.</description></item><item><title>Governance</title><link>https://pytorch-ignite.ai/about/governance/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/about/governance/</guid><description>PyTorch-Ignite Governance The purpose of this document is to formalize the governance process used by the PyTorch-Ignite project, to clarify how decisions are made and how the various elements of our community interact. This document establishes a decision-making structure that takes into account feedback from all members of the community and strives to find consensus, while avoiding any deadlocks.
This is a meritocratic, consensus-based community project. Anyone with an interest in the project can join the community, contribute to the project design and participate in the decision making process.</description></item><item><title>Talks</title><link>https://pytorch-ignite.ai/talks/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/talks/</guid><description>Talks This page contains links on our previous presentations, slides and posters.
PyData Riyadh Chapter 2022 Sprint slides
PyData Global 2021 Sprint slides
Python Bucaramanga Meetup PyTorch Community Voices 2021 Poster for PyTorch Ecosystem Day 2021
Poster for PyTorch Developer Conference 2019
Poster for PyTorch Developer Conference 2018</description></item></channel></rss>