<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Guides on PyTorch-Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/</link><description>Recent content in Guides on PyTorch-Ignite</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://pytorch-ignite.ai/how-to-guides/index.xml" rel="self" type="application/rss+xml"/><item><title>How to install PyTorch-Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/01-installation/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/01-installation/</guid><description>Install PyTorch-Ignite from pip, conda, source or use pre-built docker images</description></item><item><title>How to convert pure PyTorch code to Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/02-convert-pytorch-to-ignite/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/02-convert-pytorch-to-ignite/</guid><description>&lt;h1 id="how-to-convert-pure-pytorch-code-to-ignite">
&lt;a href="#how-to-convert-pure-pytorch-code-to-ignite" class="header-anchor">
How to convert pure PyTorch code to Ignite
&lt;/a>
&lt;/h1>&lt;p>In this guide, we will show how PyTorch code components can be converted into compact and flexible PyTorch-Ignite code.&lt;/p></description></item><item><title>How to do time profiling</title><link>https://pytorch-ignite.ai/how-to-guides/03-time-profiling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/03-time-profiling/</guid><description>Learn how to get the time breakdown for individual epochs during training, individual events, all handlers corresponding to an event, individual handlers, data loading and data processing using Engine&amp;rsquo;s State, BasicTimeProfiler and HandlersTimeProfiler.</description></item><item><title>How to use FastaiLRFinder with Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/04-fastai-lr-finder/</link><pubDate>Mon, 02 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/04-fastai-lr-finder/</guid><description>&lt;h1 id="how-to-use-fastailrfinder-with-ignite">
&lt;a href="#how-to-use-fastailrfinder-with-ignite" class="header-anchor">
How to use FastaiLRFinder with Ignite
&lt;/a>
&lt;/h1>&lt;p>This how-to guide demonstrates how we can leverage the
&lt;a href="https://pytorch.org/ignite/generated/ignite.handlers.lr_finder.FastaiLRFinder.html" target="_blank" rel="noopener noreferrer">&lt;code>FastaiLRFinder&lt;/code>&lt;/a> handler to find an optimal learning rate to train our model on. We will compare the results produced with and without using the handler for better understanding.&lt;/p></description></item><item><title>How to effectively increase batch size on limited compute</title><link>https://pytorch-ignite.ai/how-to-guides/05-gradient-accumulation/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/05-gradient-accumulation/</guid><description>&lt;h1 id="how-to-effectively-increase-batch-size-on-limited-compute">
&lt;a href="#how-to-effectively-increase-batch-size-on-limited-compute" class="header-anchor">
How to effectively increase batch size on limited compute
&lt;/a>
&lt;/h1>&lt;p>To effectively increase the batch size on limited GPU resources, follow
this simple best practice.&lt;/p></description></item><item><title>How to work with data iterators</title><link>https://pytorch-ignite.ai/how-to-guides/06-data-iterator/</link><pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/06-data-iterator/</guid><description>&lt;h1 id="how-to-work-with-data-iterators">
&lt;a href="#how-to-work-with-data-iterators" class="header-anchor">
How to work with data iterators
&lt;/a>
&lt;/h1>&lt;p>When the data provider for training or validation is an iterator
(infinite or finite with known or unknown size), here are some basic
examples of how to setup trainer or evaluator.&lt;/p></description></item><item><title>How to do Cross Validation in Ignite</title><link>https://pytorch-ignite.ai/how-to-guides/07-cross-validation/</link><pubDate>Tue, 21 Sep 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/07-cross-validation/</guid><description>&lt;h1 id="how-to-do-cross-validation-in-ignite">
&lt;a href="#how-to-do-cross-validation-in-ignite" class="header-anchor">
How to do Cross Validation in Ignite
&lt;/a>
&lt;/h1>&lt;p>This how-to guide demonstrates how we can do Cross Validation using the k-fold technique with PyTorch-Ignite and save the best results.&lt;/p>
&lt;p>Cross Validation is useful for tuning model parameters or when the available data is insufficient to properly test&lt;/p></description></item><item><title>How to create Custom Events based on Forward or Backward Pass</title><link>https://pytorch-ignite.ai/how-to-guides/08-custom-events/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/08-custom-events/</guid><description>Learn how to create custom events that depend on the loss calculated, backward pass, optimization step, etc.</description></item><item><title>How to switch data provider during training</title><link>https://pytorch-ignite.ai/how-to-guides/09-switch-data-training/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/09-switch-data-training/</guid><description>Example on how to switch data during training after some number of iterations</description></item><item><title>How to use Loggers</title><link>https://pytorch-ignite.ai/how-to-guides/10-loggers/</link><pubDate>Mon, 25 Oct 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/10-loggers/</guid><description>&lt;h1 id="how-to-use-loggers">
&lt;a href="#how-to-use-loggers" class="header-anchor">
How to use Loggers
&lt;/a>
&lt;/h1>&lt;p>This how-to guide demonstrates the usage of loggers with Ignite. As part of this guide, we will be using the
&lt;a href="https://clear.ml/docs/latest/docs/fundamentals/logger/" target="_blank" rel="noopener noreferrer">ClearML&lt;/a> logger and also highlight how this code can be easily modified to make use of other loggers. You can see all the other loggers supported
&lt;a href="https://pytorch.org/ignite/contrib/handlers.html#loggers" target="_blank" rel="noopener noreferrer">here&lt;/a>.&lt;/p></description></item><item><title>How to load checkpoint and resume training</title><link>https://pytorch-ignite.ai/how-to-guides/11-load-checkpoint/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/how-to-guides/11-load-checkpoint/</guid><description>This example demonstrates how you can save and load a checkpoint then resume training.</description></item></channel></rss>