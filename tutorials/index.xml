<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tutorials on PyTorch-Ignite</title><link>https://pytorch-ignite.ai/tutorials/</link><description>Recent content in Tutorials on PyTorch-Ignite</description><generator>Hugo -- gohugo.io</generator><atom:link href="https://pytorch-ignite.ai/tutorials/index.xml" rel="self" type="application/rss+xml"/><item><title>Distributed Training on CPUs, GPUs or TPUs</title><link>https://pytorch-ignite.ai/tutorials/intermediate/01-cifar10-distributed/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/intermediate/01-cifar10-distributed/</guid><description>&lt;h1 id="distributed-training-with-ignite-on-cifar10">
&lt;a href="#distributed-training-with-ignite-on-cifar10" class="header-anchor">
Distributed Training with Ignite on CIFAR10
&lt;/a>
&lt;/h1>&lt;p>This tutorial is a brief introduction on how you can do distributed training with Ignite on one or more CPUs, GPUs or TPUs. We will also introduce several helper functions and Ignite concepts (setup common training handlers, save to/ load from checkpoints, etc.) which you can easily incorporate in your code.&lt;/p></description></item><item><title>Getting Started</title><link>https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/</link><pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/</guid><description>&lt;h1 id="getting-started">
&lt;a href="#getting-started" class="header-anchor">
Getting Started
&lt;/a>
&lt;/h1>&lt;p>Welcome to &lt;strong>PyTorch-Ignite&lt;/strong>â€™s quick start guide that covers the
essentials of getting a project up and running while walking through
basic concepts of Ignite. In just a few lines of code, you can get your
model trained and validated. The complete code can be found at the end
of this guide.&lt;/p></description></item><item><title>Collective Communication with Ignite</title><link>https://pytorch-ignite.ai/tutorials/advanced/01-collective-communication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/advanced/01-collective-communication/</guid><description>&lt;h1 id="collective-communication-with-ignite">
&lt;a href="#collective-communication-with-ignite" class="header-anchor">
Collective Communication with Ignite
&lt;/a>
&lt;/h1>&lt;p>In this tutorial, we will see how to use advanced distributed functions like &lt;code>all_reduce()&lt;/code>, &lt;code>all_gather()&lt;/code>, &lt;code>broadcast()&lt;/code> and &lt;code>barrier()&lt;/code>. We will discuss unique use cases for all of them and represent them visually.&lt;/p></description></item><item><title>Machine Translation using PyTorch Ignite</title><link>https://pytorch-ignite.ai/tutorials/intermediate/02-machine_translation_using_pytorch_ignite/</link><pubDate>Wed, 27 Oct 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/intermediate/02-machine_translation_using_pytorch_ignite/</guid><description>&lt;h1 id="machine-translation-using-pytorch-ignite">
&lt;a href="#machine-translation-using-pytorch-ignite" class="header-anchor">
Machine Translation using PyTorch Ignite
&lt;/a>
&lt;/h1>&lt;p>This tutorial is a brief introduction on how you can train a machine translation model (or any other seq2seq model) using PyTorch Ignite.
This notebook uses Models, Dataset and Tokenizers from Huggingface, hence they can be easily replaced by other models from the ðŸ¤— Hub.&lt;/p></description></item><item><title>Transformers for Text Classification with IMDb Reviews</title><link>https://pytorch-ignite.ai/tutorials/beginner/02-transformers-text-classification/</link><pubDate>Sat, 18 Sep 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/beginner/02-transformers-text-classification/</guid><description>&lt;h1 id="transformers-for-text-classification-with-imdb-reviews">
&lt;a href="#transformers-for-text-classification-with-imdb-reviews" class="header-anchor">
Transformers for Text Classification with IMDb Reviews
&lt;/a>
&lt;/h1>&lt;p>In this tutorial we will fine tune a model from the Transformers library for text classification using PyTorch-Ignite. We will be following the
&lt;a href="https://huggingface.co/transformers/training.html" target="_blank" rel="noopener noreferrer">Fine-tuning a pretrained model&lt;/a> tutorial for preprocessing text and defining the model, optimizer and dataloaders.&lt;/p></description></item><item><title>Reinforcement Learning with Ignite</title><link>https://pytorch-ignite.ai/tutorials/intermediate/03-reinforcement-learning/</link><pubDate>Mon, 22 Nov 2021 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/intermediate/03-reinforcement-learning/</guid><description>&lt;h1 id="reinforcement-learning-with-ignite">
&lt;a href="#reinforcement-learning-with-ignite" class="header-anchor">
Reinforcement Learning with Ignite
&lt;/a>
&lt;/h1>&lt;p>In this tutorial we will implement a
&lt;a href="http://www.scholarpedia.org/article/Policy_gradient_methods" target="" rel="">policy gradient based algorithm&lt;/a> called
&lt;a href="http://www.cs.toronto.edu/~tingwuwang/REINFORCE.pdf" target="" rel="">Reinforce&lt;/a> and use it to solve OpenAI&amp;rsquo;s
&lt;a href="https://github.com/openai/gym/wiki/CartPole-v0" target="_blank" rel="noopener noreferrer">Cartpole problem&lt;/a> using PyTorch-Ignite.&lt;/p></description></item><item><title/><link>https://pytorch-ignite.ai/tutorials/others/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://pytorch-ignite.ai/tutorials/others/</guid><description>Other Tutorials Text Classification using Convolutional Neural Networks Variational Auto Encoders Convolutional Neural Networks for Classifying Fashion-MNIST Dataset Training Cycle-GAN on Horses to Zebras with Nvidia/Apex - logs on W&amp;amp;B Another training Cycle-GAN on Horses to Zebras with Native Torch CUDA AMP - logs on W&amp;amp;B Finetuning EfficientNet-B0 on CIFAR100 Hyperparameters tuning with Ax Benchmark mixed precision training on Cifar100: torch.</description></item></channel></rss>